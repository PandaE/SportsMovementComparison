"""
experimental_comparison_engine.py
é›†æˆå®éªŒæ¨¡å—çš„é«˜çº§å¯¹æ¯”å¼•æ“ï¼Œå…¼å®¹åŸæœ‰æ¥å£
"""
import cv2
import os
import tempfile
from typing import Dict, List, Tuple, Optional
from .comparison_engine import ComparisonEngine
from .experimental.frame_analyzer.frame_comparator import FrameComparator
from .experimental.frame_analyzer.pose_extractor import PoseExtractor
from .experimental.frame_analyzer.key_frame_extractor import KeyFrameExtractor
from .experimental.config.sport_configs import SportConfigs
from .pipeline.evaluation_pipeline import run_action_evaluation


class ExperimentalComparisonEngine(ComparisonEngine):
    """
    å®éªŒå¯¹æ¯”å¼•æ“ - ç»§æ‰¿åŸæœ‰æ¥å£ï¼Œæ·»åŠ é«˜çº§åˆ†æåŠŸèƒ½
    """
    
    def __init__(self, use_experimental_features: bool = True):
        """
        åˆå§‹åŒ–å¼•æ“
        
        Args:
            use_experimental_features: æ˜¯å¦å¯ç”¨å®éªŒåŠŸèƒ½
        """
        super().__init__()
        self.use_experimental = use_experimental_features
        
        if self.use_experimental:
            try:
                self.pose_extractor = PoseExtractor(backend="mediapipe")
                self.frame_comparator = FrameComparator(pose_extractor=self.pose_extractor)
                self.key_frame_extractor = KeyFrameExtractor()
                self.experimental_ready = True
                print("å®éªŒæ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"å®éªŒæ¨¡å—åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æ¨¡å¼: {e}")
                self.experimental_ready = False
        else:
            self.experimental_ready = False
    
    def compare(self, user_video_path: str, standard_video_path: str, 
                sport: str = "badminton", action: str = "clear") -> Dict:
        """
        å¯¹æ¯”ä¸¤ä¸ªè§†é¢‘
        
        Args:
            user_video_path: ç”¨æˆ·è§†é¢‘è·¯å¾„
            standard_video_path: æ ‡å‡†è§†é¢‘è·¯å¾„
            sport: è¿åŠ¨ç±»å‹
            action: åŠ¨ä½œç±»å‹
            
        Returns:
            å¯¹æ¯”ç»“æœå­—å…¸
        """
        if self.experimental_ready and self.use_experimental:
            return self._experimental_compare(user_video_path, standard_video_path, sport, action)
        else:
            # å›é€€åˆ°åŸæœ‰çš„dummyå®ç°
            return super().compare(user_video_path, standard_video_path)
    
    def _experimental_compare(self, user_video_path: str, standard_video_path: str, 
                            sport: str, action: str) -> Dict:
        """å®éªŒæ¨¡å—çš„å¯¹æ¯”å®ç°"""
        try:
            # 1. è·å–è¿åŠ¨é…ç½®
            config = SportConfigs.get_config(sport, action)
            
            # 2. è‡ªåŠ¨æå–å…³é”®å¸§
            print(f"ğŸ¯ å¼€å§‹æå–å…³é”®å¸§: {sport} - {action}")
            user_stage_frames = self.key_frame_extractor.extract_stage_images(user_video_path, sport, action)
            standard_stage_frames = self.key_frame_extractor.extract_stage_images(standard_video_path, sport, action)
            
            if not user_stage_frames or not standard_stage_frames:
                return self._create_error_result("æ— æ³•æå–æœ‰æ•ˆçš„å…³é”®å¸§")
            
            print(f"âœ… å…³é”®å¸§æå–å®Œæˆï¼Œå…±æå– {len(user_stage_frames)} ä¸ªé˜¶æ®µçš„å¸§")
            
            # 3. æ‰§è¡Œå¤šé˜¶æ®µå¯¹æ¯”åˆ†æ (æ—§å¯¹æ¯”é€»è¾‘ä¿ç•™)
            results = []
            overall_score = 0.0
            
            for stage in config.stages:
                stage_name = stage.name
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„å…³é”®å¸§
                if stage_name in user_stage_frames and stage_name in standard_stage_frames:
                    stage_result = self._analyze_stage(
                        user_stage_frames[stage_name], 
                        standard_stage_frames[stage_name], 
                        stage
                    )
                    results.append(stage_result)
                    overall_score += stage_result['score'] * stage.weight
                    print(f"   ğŸ“Š {stage_name}: {stage_result['score']:.2f} (æƒé‡: {stage.weight})")
                else:
                    print(f"   âš ï¸  {stage_name}: ç¼ºå°‘å…³é”®å¸§ï¼Œè·³è¿‡åˆ†æ")
            
            # 4. ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ– (ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„å…³é”®å¸§å¯¹)
            comparison_images = {}
            if user_stage_frames and standard_stage_frames:
                first_stage = list(user_stage_frames.keys())[0]
                comparison_images = self._generate_comparison_images(
                    user_stage_frames[first_stage], 
                    standard_stage_frames[first_stage], 
                    results
                )
            
            # 5. æ„å»ºå…¼å®¹çš„è¿”å›æ ¼å¼ï¼ŒåŒ…å«å…³é”®å¸§ä¿¡æ¯
            # è·å–å…³é”®å¸§ä½ç½®ä¿¡æ¯ç”¨äºä¼ é€’
            user_frame_positions = self.key_frame_extractor.extract_stage_frames(user_video_path, sport, action)
            standard_frame_positions = self.key_frame_extractor.extract_stage_frames(standard_video_path, sport, action)
            
            result = self._format_experimental_results(
                overall_score, results, comparison_images, user_video_path, standard_video_path,
                user_frame_positions, standard_frame_positions
            )
            
            # 6. æ·»åŠ å…³é”®å¸§ä¿¡æ¯åˆ°ç»“æœä¸­
            result['key_frame_info'] = {
                'user_frames': user_frame_positions,
                'standard_frames': standard_frame_positions,
                'extraction_method': 'intelligent' if self.key_frame_extractor.use_intelligent_extraction else 'time_based',
                'sport': sport,
                'action': action
            }
            
            print(f"ğŸ† æ—§å¯¹æ¯”åˆ†æå®Œæˆï¼Œæ€»åˆ†: {overall_score:.2f}")

            # 7. æ–°å¢ï¼šåŸºäº Metrics + Evaluation çš„ç»Ÿä¸€è¯„åˆ† (ä»…ä½¿ç”¨ç”¨æˆ·è§†é¢‘å…³é”®å¸§ï¼Œä¸å†ä¸æ ‡å‡†é€å¸§å·®åˆ†)
            try:
                # å¤ç”¨å·²æŠ½å–çš„ç”¨æˆ·é˜¶æ®µå¸§ä½œä¸º pose è®¡ç®—è¾“å…¥
                # ä»…å½“ç”¨æˆ·å¸§å­˜åœ¨æ—¶æ‰§è¡Œ
                if user_stage_frames:
                    # æå–æ¯é˜¶æ®µ poseï¼ˆå•å¸§ï¼‰
                    stage_pose_map = {}
                    for stage in config.stages:
                        if stage.name in user_stage_frames:
                            pose = self.frame_comparator.pose_extractor.extract_pose_from_image(user_stage_frames[stage.name], 0)
                            if pose:
                                stage_pose_map[stage.name] = (pose, 0)
                    if stage_pose_map:
                        metrics_result, evaluation = run_action_evaluation(config, stage_pose_map, language='zh_CN')
                        result['new_evaluation'] = {
                            'overall_score': evaluation.score,
                            'summary': evaluation.summary,
                            'stages': [
                                {
                                    'name': st.name,
                                    'score': st.score,
                                    'measurements': [
                                        {
                                            'key': mv.key,
                                            'value': mv.value,
                                            'score': mv.score,
                                            'passed': mv.passed,
                                            'feedback': mv.feedback,
                                        } for mv in st.measurements
                                    ]
                                } for st in evaluation.stages
                            ]
                        }
                        print("ğŸ†• æ–°è¯„ä»·æ¨¡å—è¾“å‡ºå®Œæˆ (new_evaluation é”®)")
            except Exception as ee:
                print(f"æ–°è¯„ä»·æ¨¡å—æ‰§è¡Œå¤±è´¥: {ee}")

            return result
            
        except Exception as e:
            print(f"å®éªŒåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._create_error_result(f"åˆ†æå¤±è´¥: {str(e)}")
    
    def _extract_key_frames(self, video_path: str, num_frames: int = 1) -> List:
        """ä»è§†é¢‘ä¸­æå–å…³é”®å¸§"""
        frames = []
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            return frames
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # ç®€å•ç­–ç•¥ï¼šæå–ä¸­é—´å¸§
        frame_indices = [total_frames // 2] if num_frames == 1 else \
                       [int(i * total_frames / num_frames) for i in range(num_frames)]
        
        for frame_idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                frames.append(frame)
        
        cap.release()
        return frames
    
    def _analyze_stage(self, user_frame, standard_frame, stage_config) -> Dict:
        """åˆ†æå•ä¸ªé˜¶æ®µ"""
        try:
            # ä½¿ç”¨analyze_frameæ–¹æ³•è¿›è¡Œå¸§åˆ†æ
            user_analysis = self.frame_comparator.analyze_frame(user_frame, stage_config)
            standard_analysis = self.frame_comparator.analyze_frame(standard_frame, stage_config)
            
            if not user_analysis or not standard_analysis:
                return {
                    'stage_name': stage_config.name,
                    'score': 0.0,
                    'measurements': [],
                    'error': 'å¸§åˆ†æå¤±è´¥'
                }
            
            # æ‰§è¡Œå¸§å¯¹æ¯”
            comparison_result = self.frame_comparator.compare_frames(
                user_analysis, standard_analysis, stage_config
            )
            
            # è½¬æ¢å¯¹æ¯”ç»“æœæ ¼å¼
            enhanced_measurements = []
            for measurement_comp in comparison_result.measurements:
                enhanced_measurement = {
                    'measurement_name': measurement_comp.measurement_name,
                    'user_value': measurement_comp.user_value,
                    'standard_value': measurement_comp.standard_value,
                    'difference': measurement_comp.difference,
                    'percentage_diff': measurement_comp.percentage_diff,
                    'is_within_tolerance': measurement_comp.is_within_tolerance,
                    'tolerance_range': measurement_comp.tolerance_range,
                    'unit': 'Â°',  # å¤§éƒ¨åˆ†æ˜¯è§’åº¦æµ‹é‡
                    'keypoints': [],  # å¯ä»¥ä»stage_config.measurementsä¸­æŸ¥æ‰¾
                    'score': 1.0 if measurement_comp.is_within_tolerance else 0.5
                }
                
                # æ‰¾åˆ°å¯¹åº”çš„è§„åˆ™æ¥è·å–keypointså’Œunit
                for rule in stage_config.measurements:
                    if rule.name == measurement_comp.measurement_name:
                        enhanced_measurement['keypoints'] = rule.keypoints
                        enhanced_measurement['unit'] = rule.unit
                        break
                
                enhanced_measurements.append(enhanced_measurement)
            
            return {
                'stage_name': stage_config.name,
                'score': comparison_result.overall_score / 100.0,  # è½¬æ¢ä¸º0-1èŒƒå›´
                'measurements': enhanced_measurements,
                'suggestions': self._generate_suggestions_from_comparison(comparison_result)
            }
            
            # å¢å¼ºæµ‹é‡ç»“æœä¿¡æ¯
            enhanced_measurements = []
            for measurement in comparison_result['measurement_results']:
                # æ‰¾åˆ°å¯¹åº”çš„è§„åˆ™é…ç½®
                rule = next((r for r in stage_config.measurements 
                           if r.name == measurement.get('measurement_name')), None)
                
                enhanced_measurement = {
                    'measurement_name': measurement.get('measurement_name'),
                    'user_value': measurement.get('user_value'),
                    'standard_value': measurement.get('standard_value'),
                    'difference': measurement.get('difference'),
                    'percentage_diff': measurement.get('percentage_diff', 0),
                    'is_within_tolerance': measurement.get('is_within_tolerance'),
                    'tolerance_range': measurement.get('tolerance_range'),
                    'unit': rule.unit if rule else 'Â°',
                    'keypoints': rule.keypoints if rule else [],
                    'measurement_type': rule.measurement_type if rule else 'unknown',
                    'description': rule.description if rule else '',
                    'weight': rule.weight if rule else 1.0,
                    'score': measurement.get('score', 0)
                }
                enhanced_measurements.append(enhanced_measurement)
            
            return {
                'stage_name': stage_config.name,
                'score': comparison_result['overall_score'],
                'measurements': enhanced_measurements,
                'suggestions': self._generate_suggestions(comparison_result),
                'processing_info': {
                    'pose_detection_confidence': {
                        'user': self._get_pose_confidence(user_pose),
                        'standard': self._get_pose_confidence(standard_pose)
                    },
                    'keypoints_detected': {
                        'user': self._count_valid_keypoints(user_pose),
                        'standard': self._count_valid_keypoints(standard_pose)
                    }
                }
            }
            
        except Exception as e:
            return {
                'stage_name': stage_config.name,
                'score': 0.0,
                'measurements': [],
                'error': f'åˆ†æé”™è¯¯: {str(e)}'
            }
    
    def _generate_comparison_images(self, user_frame, standard_frame, results) -> Dict:
        """ç”Ÿæˆå¯¹æ¯”å¯è§†åŒ–å›¾åƒ"""
        comparison_images = {}
        
        try:
            # æå–å¹¶å¯è§†åŒ–å§¿æ€
            user_pose = self.pose_extractor.extract_pose_from_image(user_frame)
            standard_pose = self.pose_extractor.extract_pose_from_image(standard_frame)
            
            if user_pose and standard_pose:
                user_vis = self.pose_extractor.visualize_pose(user_frame, user_pose)
                standard_vis = self.pose_extractor.visualize_pose(standard_frame, standard_pose)
                
                # ä¿å­˜ä¸´æ—¶å›¾åƒ
                temp_dir = tempfile.gettempdir()
                user_img_path = os.path.join(temp_dir, "user_pose_analysis.jpg")
                standard_img_path = os.path.join(temp_dir, "standard_pose_analysis.jpg")
                
                cv2.imwrite(user_img_path, user_vis)
                cv2.imwrite(standard_img_path, standard_vis)
                
                comparison_images = {
                    'user_pose': user_img_path,
                    'standard_pose': standard_img_path
                }
        
        except Exception as e:
            print(f"ç”Ÿæˆå¯¹æ¯”å›¾åƒå¤±è´¥: {e}")
        
        return comparison_images
    
    def _generate_suggestions_from_comparison(self, comparison_result) -> List[str]:
        """ä»FrameComparisonç»“æœç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        for measurement in comparison_result.measurements:
            name = measurement.measurement_name
            if not measurement.is_within_tolerance:
                if 'è§’åº¦' in name or 'angle' in name.lower():
                    if measurement.difference > 0:
                        suggestions.append(f"{name}åå¤§ï¼Œå»ºè®®è°ƒæ•´æ‰‹è‡‚è§’åº¦")
                    else:
                        suggestions.append(f"{name}åå°ï¼Œå»ºè®®åŠ å¤§æ‰‹è‡‚è§’åº¦")
                else:
                    suggestions.append(f"{name}éœ€è¦è°ƒæ•´")
            else:
                suggestions.append(f"{name}è¡¨ç°è‰¯å¥½")
        
        if not suggestions:
            suggestions.append("åŠ¨ä½œæ ‡å‡†ï¼Œç»§ç»­ä¿æŒï¼")
        
        return suggestions
    
    def _generate_suggestions(self, comparison_result: Dict) -> List[str]:
        """æ ¹æ®å¯¹æ¯”ç»“æœç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        for measurement in comparison_result.get('measurement_results', []):
            score = measurement.get('score', 0)
            name = measurement.get('measurement_name', 'æœªçŸ¥æµ‹é‡')
            
            if score < 0.6:
                if 'è§’åº¦' in name:
                    suggestions.append(f"{name}åå·®è¾ƒå¤§ï¼Œæ³¨æ„è°ƒæ•´æ‰‹è‡‚å§¿åŠ¿")
                elif 'é«˜åº¦' in name:
                    suggestions.append(f"{name}ä¸å¤Ÿç†æƒ³ï¼Œæ³¨æ„èº«ä½“å§¿æ€")
                else:
                    suggestions.append(f"{name}éœ€è¦æ”¹è¿›")
            elif score < 0.8:
                suggestions.append(f"{name}åŸºæœ¬æ­£ç¡®ï¼Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        if not suggestions:
            suggestions.append("åŠ¨ä½œæ ‡å‡†ï¼Œç»§ç»­ä¿æŒï¼")
        
        return suggestions
    
    def _get_measurement_type_description(self, measurement_type: str) -> str:
        """è·å–æµ‹é‡ç±»å‹çš„æè¿°"""
        descriptions = {
            'angle': 'è§’åº¦æµ‹é‡ - é€šè¿‡ä¸‰ä¸ªå…³é”®ç‚¹è®¡ç®—å¤¹è§’',
            'distance': 'è·ç¦»æµ‹é‡ - è®¡ç®—ä¸¤ç‚¹é—´çš„ç›´çº¿è·ç¦»',
            'height': 'é«˜åº¦æµ‹é‡ - ç›¸å¯¹äºå‚è€ƒç‚¹çš„å‚ç›´è·ç¦»',
            'horizontal_distance': 'æ°´å¹³è·ç¦» - ä¸¤ç‚¹é—´çš„æ°´å¹³è·ç¦»',
            'vertical_distance': 'å‚ç›´è·ç¦» - ä¸¤ç‚¹é—´çš„å‚ç›´è·ç¦»',
            'ratio': 'æ¯”ä¾‹æµ‹é‡ - è®¡ç®—ä¸¤ä¸ªè·ç¦»çš„æ¯”å€¼',
            'position': 'ä½ç½®æµ‹é‡ - å…³é”®ç‚¹çš„ç»å¯¹ä½ç½®'
        }
        return descriptions.get(measurement_type, f'è‡ªå®šä¹‰æµ‹é‡ç±»å‹: {measurement_type}')
    
    def _get_pose_confidence(self, pose) -> float:
        """è·å–å§¿æ€æ£€æµ‹çš„å¹³å‡ç½®ä¿¡åº¦"""
        if not pose:
            return 0.0
        
        confidences = []
        keypoints = [
            pose.nose, pose.left_shoulder, pose.right_shoulder,
            pose.left_elbow, pose.right_elbow, pose.left_wrist, pose.right_wrist,
            pose.left_hip, pose.right_hip, pose.left_knee, pose.right_knee,
            pose.left_ankle, pose.right_ankle
        ]
        
        for kp in keypoints:
            if kp and hasattr(kp, 'confidence'):
                confidences.append(kp.confidence)
        
        return sum(confidences) / len(confidences) if confidences else 0.0
    
    def _count_valid_keypoints(self, pose) -> int:
        """ç»Ÿè®¡æœ‰æ•ˆå…³é”®ç‚¹æ•°é‡"""
        if not pose:
            return 0
        
        count = 0
        keypoints = [
            pose.nose, pose.left_shoulder, pose.right_shoulder,
            pose.left_elbow, pose.right_elbow, pose.left_wrist, pose.right_wrist,
            pose.left_hip, pose.right_hip, pose.left_knee, pose.right_knee,
            pose.left_ankle, pose.right_ankle
        ]
        
        for kp in keypoints:
            if kp and (not hasattr(kp, 'confidence') or kp.confidence > 0.5):
                count += 1
        
        return count
    
    def _format_experimental_results(self, overall_score: float, stage_results: List, 
                                   comparison_images: Dict, user_video_path: str, 
                                   standard_video_path: str, user_frame_positions: Dict[str, int] = None,
                                   standard_frame_positions: Dict[str, int] = None) -> Dict:
        """æ ¼å¼åŒ–ç»“æœä»¥å…¼å®¹åŸæœ‰æ¥å£å¹¶æä¾›é«˜çº§åˆ†ææ•°æ®"""
        
        # æ„å»ºkey_movementsåˆ—è¡¨ï¼ˆå…¼å®¹åŸæ¥å£ï¼‰
        key_movements = []
        stages_data = {}  # ä¸ºé«˜çº§åˆ†æçª—å£æä¾›çš„é˜¶æ®µæ•°æ®
        
        for i, stage_result in enumerate(stage_results):
            stage_name = stage_result.get('stage_name', f'é˜¶æ®µ{i+1}')
            score = stage_result.get('score', 0)
            suggestions = stage_result.get('suggestions', [])
            measurements = stage_result.get('measurements', [])
            
            # ç”Ÿæˆæ‘˜è¦
            if score >= 0.8:
                summary = f"{stage_name}: åŠ¨ä½œæ ‡å‡† (å¾—åˆ†: {score:.1%})"
            elif score >= 0.6:
                summary = f"{stage_name}: åŸºæœ¬æ­£ç¡®ï¼Œæœ‰æ”¹è¿›ç©ºé—´ (å¾—åˆ†: {score:.1%})"
            else:
                summary = f"{stage_name}: éœ€è¦æ”¹è¿› (å¾—åˆ†: {score:.1%})"
            
            # ç®€åŒ–çš„è¯¦ç»†æµ‹é‡ä¿¡æ¯ - åªæ˜¾ç¤ºæ ¸å¿ƒå¯¹æ¯”æ•°æ®
            measurement_details = []
            stage_measurements = []  # ä¸ºé«˜çº§åˆ†æçª—å£å‡†å¤‡çš„æµ‹é‡æ•°æ®
            
            for m in measurements:
                measurement_name = m.get('measurement_name', 'æµ‹é‡')
                user_value = m.get('user_value', 0)
                standard_value = m.get('standard_value', 0)
                unit = m.get('unit', '')
                difference = m.get('difference', 0)
                is_within_tolerance = m.get('is_within_tolerance', False)
                keypoints = m.get('keypoints', [])
                
                # æ ¸å¿ƒå¯¹æ¯”ä¿¡æ¯
                basic_info = f"â€¢ {measurement_name}: ç”¨æˆ· {user_value:.1f}{unit} vs æ ‡å‡† {standard_value:.1f}{unit}"
                measurement_details.append(basic_info)
                
                # ç®€æ´çš„å·®å¼‚è¯´æ˜
                if is_within_tolerance:
                    status = "âœ“ è¾¾æ ‡"
                else:
                    direction = "åå¤§" if difference > 0 else "åå°"
                    status = f"âœ— {direction} {abs(difference):.1f}{unit}"
                
                measurement_details.append(f"  {status}")
                
                # æµ‹é‡ç‚¹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if keypoints:
                    measurement_details.append(f"  æµ‹é‡ç‚¹: {' â†’ '.join(keypoints)}")
                
                # ä¸ºé«˜çº§åˆ†æçª—å£å‡†å¤‡æµ‹é‡æ•°æ®
                stage_measurements.append({
                    'rule_name': measurement_name,
                    'user_value': user_value,
                    'standard_value': standard_value,
                    'is_within_range': is_within_tolerance,
                    'measurement_points': keypoints
                })
            
            # ä¸ºé«˜çº§åˆ†æçª—å£æ„å»ºé˜¶æ®µæ•°æ®ï¼Œä½¿ç”¨ä¼ å…¥çš„å…³é”®å¸§ä½ç½®
            user_frame = user_frame_positions.get(stage_name, 0) if user_frame_positions else 0
            standard_frame = standard_frame_positions.get(stage_name, 0) if standard_frame_positions else 0
            
            stages_data[stage_name] = {
                'user_frame': user_frame,
                'standard_frame': standard_frame,
                'stage_info': {
                    'score': score * 100,
                    'status': summary
                },
                'measurements': stage_measurements
            }
            
            key_movements.append({
                'name': stage_name,
                'user_image': comparison_images.get('user_pose'),
                'standard_image': comparison_images.get('standard_pose'),
                'summary': summary,
                'suggestion': '; '.join(suggestions) if suggestions else 'ç»§ç»­ä¿æŒ',
                'detailed_measurements': measurement_details,
                'measurements_data': measurements,  # ä¿ç•™åŸå§‹æ•°æ®ç”¨äºè¯¦ç»†å±•ç¤º
                'score': score
            })
        
        return {
            'score': int(overall_score * 100),  # è½¬æ¢ä¸ºç™¾åˆ†åˆ¶
            'detailed_score': overall_score,
            'key_movements': key_movements,
            'analysis_type': 'experimental_with_key_frames',
            'sport': 'ç¾½æ¯›çƒ',
            'action': 'æ­£æ‰‹é«˜è¿œçƒ',
            'user_video_path': user_video_path,
            'standard_video_path': standard_video_path,
            'comparison_info': {
                'user_frame': f"ä» {user_video_path} è‡ªåŠ¨æå–çš„å…³é”®å¸§",
                'standard_frame': f"ä» {standard_video_path} è‡ªåŠ¨æå–çš„å…³é”®å¸§",
                'rules_applied': [m.get('measurement_name') for sr in stage_results for m in sr.get('measurements', [])],
                'total_comparisons': sum(len(sr.get('measurements', [])) for sr in stage_results),
                'extraction_method': 'åŸºäºæ—¶é—´ç­‰åˆ†çš„è‡ªåŠ¨å…³é”®å¸§æå–'
            },
            # ä¸ºé«˜çº§åˆ†æçª—å£æ·»åŠ é˜¶æ®µæ•°æ®
            'stages': stages_data,
            'comparison_images': comparison_images,
            'analysis_summary': {
                'total_stages': len(stage_results),
                'avg_score': overall_score * 100,
                'suggestions': [s for sr in stage_results for s in sr.get('suggestions', [])],
                'key_frame_extraction': 'âœ… å·²è‡ªåŠ¨æå–å…³é”®å¸§'
            }
        }
    
    def _create_error_result(self, error_message: str) -> Dict:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'score': 0,
            'error': error_message,
            'key_movements': [{
                'name': 'åˆ†æé”™è¯¯',
                'user_image': None,
                'standard_image': None,
                'summary': error_message,
                'suggestion': 'è¯·æ£€æŸ¥è§†é¢‘æ–‡ä»¶æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ'
            }],
            'analysis_type': 'error'
        }
    
    def get_available_configs(self) -> List[Tuple[str, str]]:
        """è·å–å¯ç”¨çš„è¿åŠ¨é…ç½®"""
        if self.experimental_ready:
            return SportConfigs.list_available_configs()
        else:
            return [("Badminton", "Clear Shot (Basic)")]
    
    def set_experimental_mode(self, enabled: bool):
        """è®¾ç½®å®éªŒæ¨¡å¼å¼€å…³"""
        self.use_experimental = enabled and self.experimental_ready
        print(f"å®éªŒæ¨¡å¼: {'å¯ç”¨' if self.use_experimental else 'ç¦ç”¨'}")